deploy_user=zhongtai
service_hosts=node100

# data directory
data_directory=/data/hadoop-3.2.4
pid_dir=/data/hadoop-3.2.4/pid
log_dir=/data/hadoop-3.2.4/log
yarn_timeline_dir=/data/hadoop-3.2.4/yarn/timeline


[yarn_site]
yarn.nodemanager.aux-services mapreduce_shuffle
yarn.resourcemanager.hostname node111
yarn.resourcemanager.ha.automatic-failover.enabled true
hadoop.zk.address node100:2181
yarn.resourcemanager.recovery.enabled true
yarn.resourcemanager.store.class org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
yarn.resourcemanager.state-store.max-completed-applications 100
yarn.resourcemanager.max-completed-applications 100
yarn.resourcemanager.zk-max-znode-size.bytes 4194304
yarn.nodemanager.resource.pcores-vcores-multiplier 1
yarn.nodemanager.resource.cpu-vcores 40
yarn.scheduler.minimum-allocation-vcores 1
yarn.scheduler.maximum-allocation-vcores 4
yarn.nodemanager.vmem-pmem-ratio 2.1
yarn.nodemanager.resource.memory-mb 131072
yarn.scheduler.minimum-allocation-mb 1024
yarn.scheduler.maximum-allocation-mb 12288
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage 100.0
yarn.nodemanager.aux-services.spark_shuffle.class org.apache.spark.network.yarn.YarnShuffleService
yarn.nodemanager.pmem-check-enabled false
yarn.nodemanager.vmem-check-enabled false
yarn.nodemanager.vmem-pmem-ratio 2.1
yarn.log-aggregation-enable true
yarn.log-aggregation.retain-seconds 2592000
yarn.log.server.url http://node100:19888/jobhistory/logs


[mapred_site]
mapreduce.framework.name yarn
mapreduce.jobhistory.address node100:10020
mapreduce.jobhistory.webapp.address node100:19888
mapreduce.application.classpath $HADOOP_HOME/share/hadoop/mapreduce/*,$HADOOP_HOME/share/hadoop/mapreduce/lib/*
yarn.app.mapreduce.am.env HADOOP_MAPRED_HOME=${HADOOP_HOME}
mapreduce.map.env HADOOP_MAPRED_HOME=${HADOOP_HOME}
mapreduce.reduce.env HADOOP_MAPRED_HOME=${HADOOP_HOME}
mapreduce.task.io.sort.mb 200
mapreduce.task.io.sort.factor 20
mapreduce.map.memory.mb 2048
mapreduce.reduce.shuffle.parallelcopies 10
mapreduce.reduce.shuffle.input.buffer.percent 0.80
mapreduce.reduce.shuffle.merge.percent 0.75
mapreduce.reduce.memory.mb 2048
mapreduce.task.timeout 600000
mapreduce.map.output.compress true
mapreduce.map.output.compress.codec org.apache.hadoop.io.compress.SnappyCodec
mapreduce.output.fileoutputformat.compress true
mapreduce.output.fileoutputformat.compress.codec org.apache.hadoop.io.compress.GzipCodec
mapreduce.output.fileoutputformat.compress.type BLOCK
mapreduce.job.ubertask.enable true


[capacity_scheduler]
yarn.scheduler.capacity.resource-calculator org.apache.hadoop.yarn.util.resource.DominantResourceCalculator


[workers]
workers_ip_arrays=node100


[hadoop_env]
export JAVA_HOME:/opt/jdk1.8.0_201
export HADOOP_PID_DI:/data/hadoop-3.2.4/pid
export HADOOP_MAPRED_PID_DIR:/data/hadoop-3.2.4/pid
export HADOOP_LOG_DIR:/data/hadoop-3.2.4/log
export HDFS_NAMENODE_OPTS:"-Dhadoop.security.logger=INFO,RFAS -Xmx4096m"
export HDFS_DATANODE_OPTS:"-Dhadoop.security.logger=ERROR,RFAS -Xmx4096m"
export HDFS_JOURNALNODE_OPTS:"-Xmx4096m"


[yarn_env]
export YARN_PID_DIR:/data/hadoop-3.2.4/pid
export YARN_RESOURCEMANAGER_OPTS:-Drm.audit.logger=INFO,RMAUDIT -Xmx4096m"
export YARN_NODEMANAGER_OPTS:"-Dnm.audit.logger=INFO,NMAUDIT -Xmx4096m"


[mapred_env]
export HADOOP_MAPRED_PID_DI:/data/hadoop-3.2.4/pid
export MAPRED_HISTORYSERVER_OPTS:"-Xmx4096m"
